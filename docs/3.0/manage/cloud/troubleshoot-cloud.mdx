---
title: What's new in Prefect 3.0
sidebarTitle: What's new
---

Prefect 3.0 introduces a number of enhancements to the OSS product: a new events & automations backend for event-driven workflows and observability, improved runtime performance, autonomous task execution and a streamlined caching layer based on transactional semantics.

Most Prefect 2.0 users can upgrade without changes to their existing workflows. Please review the [upgrade guide](/3.0/resources/upgrade-to-prefect-3) for more information.

<Info>
**Prefect 2.0** refers to the 2.x lineage of the open source prefect package, and **Prefect 3.0** refers exclusively to the 3.x lineage of the prefect package. Neither version is strictly tied to any aspect of Prefect's commercial product, [Prefect Cloud](/3.0/manage/cloud). 
</Info>

## Open source events and automation system

One of the largest features in Prefect 3.0 is the introduction of the events and automation system to the open source package. Previously exclusive to Prefect Cloud, this system now allows all users to create event-driven workflows and automate their system based on the presence or absence of observable events. 

With this new capability, you can trigger actions based on specific event payloads, cancel runs if certain conditions aren't met, or automate workflow runs based on external events. For instance, you could initiate a data processing pipeline automatically when a new file lands in an S3 bucket. The system also enables you to receive notifications for various system health events, giving you greater visibility and control over your workflows.

## New transactional interface

Another major addition in Prefect 3.0 is the new transactional interface. This powerful feature makes it easier than ever to build resilient and idempotent pipelines. With the transactional interface, you can group tasks into transactions, automatically roll back side effects on failure, and significantly improve your pipeline's idempotency and resilience.

For example, you can define rollback behaviors for your tasks, ensuring that any side effects are cleanly reversed if a transaction fails. This is particularly useful for maintaining data consistency in complex workflows involving multiple steps or external systems.

## Flexible task execution

Prefect 3.0 has no restrictions on where tasks can run. Tasks can be nested within other tasks, allowing for more flexible and modular workflows; they can also be called outside of flows, essentially enabling Prefect to function as a background task service. You can now run tasks autonomously, apply them asynchronously, or delay their execution as needed. This flexibility opens up new possibilities for task management and execution strategies in your data pipelines.

## Enhanced client-side engine

Prefect 3.0 comes with a thoroughly reworked client-side engine that brings several improvements to the table. You can now nest tasks within other tasks, adding a new level of modularity to your workflows. The engine also supports generator tasks, allowing for more flexible and efficient handling of iterative processes.

One of the most significant changes is that all code now runs on the main thread by default. This change improves performance and leads to more intuitive behavior, especially when dealing with shared resources or non-thread-safe operations.

## Improved artifacts and variables

Prefect 3.0 enhances the artifacts system with new types, including progress bars and image artifacts. These additions allow for richer, more informative task outputs, improving the observability of your workflows.

The variables system has also been upgraded to support arbitrary JSON, not just strings. This expansion allows for more complex and structured data to be stored and retrieved as variables, increasing the flexibility of your workflow configurations.

## Workers

Workers were first introduced in Prefect 2.0 as next-generation agents, and are now standard in Prefect 3.0. Workers offer a stronger governance model for infrastructure, improved monitoring of jobs and work pool/queue health, and more flexibility in choosing compute layers, resulting in a more robust and scalable solution for managing the execution of your workflows across various environments.

Worker logs are now sent to the API only if a worker ID is present, indicating a connection to Prefect Cloud. This change simplifies the logging configuration and ensures logs are only sent when supported by the backend. The `PREFECT_EXPERIMENTS_WORKER_LOGGING_TO_API_ENABLED` environment variable has been removed, and users should update their configurations to align with the new logging behavior.

## Performance enhancements

Prefect 3.0 doesn't just bring new features; it also delivers significant performance improvements. Users running massively parallel workflows on distributed systems such as Dask and Ray will notice substantial speedups. In some benchmark cases, we've observed up to a 98% reduction in runtime overhead. These performance gains translate directly into faster execution times and more efficient resource utilization for your data pipelines.

## Release notes

See release notes for each released version in the [Gitub repository](https://github.com/PrefectHQ/prefect/releases).

# General troubleshooting

The first troubleshooting step is to confirm that you are running the latest version of Prefect.
If you are not, upgrade (see below) to the latest version, since the issue may have already been fixed. 
Beyond that, there are several categories of errors:

* The issue may be in your flow code, in which case you should carefully read the [logs](#logs).
* The issue could be with how you are authenticated, and whether or not you are connected to [Cloud](#cloud).
* The issue might have to do with how your code is [executed](#execution).

## Upgrade

Prefect is constantly evolving by adding new features and fixing bugs. A patch may have already been 
identified and released. Search existing [issues](https://github.com/PrefectHQ/prefect/issues) for similar reports 
and check out the [Release Notes](https://github.com/PrefectHQ/prefect/releases). 

Upgrade to the newest version with the following command:

```bash
pip install --upgrade prefect
```

Different components may use different versions of Prefect:

- **Cloud** is generally the newest version. Cloud is continuously deployed by the Prefect team. 
When using a self-hosted server, you can control this version.
- **Workers** change versions infrequently, and are usually the latest version at the time of creation. 
Workers provision infrastructure for flow runs, so upgrading them may help with infrastructure problems.
- **Flows** could use a different version than the worker that created them, especially when running in different environments. 
Suppose your worker and flow both use the latest official Docker image, but your worker was created a month ago. 
Your worker is often an older version than your flow.

<Note>
**Integration Versions**

[Integrations](/integrations/) are versioned and released independently of the core Prefect library. 
They should be upgraded simultaneously with the core library, using the same method.
</Note>

## Logs

In many cases, there is an informative stack trace in Prefect's [logs](/3.0/develop/logging/). 
**Read it carefully**, locate the source of the error, and try to identify the cause.

There are two types of logs:

- **Flow and task logs** are always scoped to a flow. They are sent to Prefect and are viewable in the UI.
- **Worker logs** are not scoped to a flow and may have more information on what happened before the flow started. 
These logs are generally only available where the worker is running.

If your flow and task logs are empty, there may have been an infrastructure issue that prevented your flow from starting. 
Check your worker logs for more details.

If there is no clear indication of what went wrong, try updating the logging level from the default `INFO` level 
to the `DEBUG` level. [Settings](https://prefect-python-sdk-docs.netlify.app/prefect/settings/) such as the logging level are propagated 
from the worker environment to the flow run environment. Set them with environment variables or the `prefect config set` CLI:

```bash
# Using the CLI
prefect config set PREFECT_LOGGING_LEVEL=DEBUG

# Using environment variables
export PREFECT_LOGGING_LEVEL=DEBUG
```

The `DEBUG` logging level produces a high volume of logs, so consider setting it back to `INFO` once any issues are resolved.

## Cloud

When using Prefect Cloud, there are the additional concerns of authentication and authorization. 
The Prefect API authenticates users and service accounts, collectively known as actors, with API keys. 
Missing, incorrect, or expired API keys result in a 401 response with detail `Invalid authentication credentials`. 
Use the following command to check your authentication, replacing `$PREFECT_API_KEY` with your API key:

```bash
curl -s -H "Authorization: Bearer $PREFECT_API_KEY" "https://api.prefect.cloud/api/me/"
```

<Note>
**Users vs Service Accounts**

[Service accounts](/3.0/manage/cloud/manage-users/service-accounts/) (sometimes referred to as bots),  
represent non-human actors that interact with Prefect such as workers and CI/CD systems. 
Each human that interacts with Prefect should be represented as a user. 
User API keys start with `pnu_` and service account API keys start with `pnb_`.
</Note>

Actors can be members of [workspaces](/3.0/manage/cloud/workspaces/). An actor attempting an action in a 
workspace they are not a member of results in a 404 response. Use the following command to check your actor's workspace memberships:

```bash
curl -s -H "Authorization: Bearer $PREFECT_API_KEY" "https://api.prefect.cloud/api/me/workspaces"
```

<Note>
**Formatting JSON**

Python comes with a helpful [tool](https://docs.python.org/3/library/json.html#module-json.tool) for formatting JSON. 
Append the following to the end of the command above to make the output more readable: `| python -m json.tool`
</Note>

Make sure your actor is a member of the workspace you are working in. Within a workspace, 
an actor has a [role](/3.0/manage/cloud/manage-users/manage-roles/) which grants them certain permissions. 
Insufficient permissions result in an error. For example, starting a worker with the **Viewer** role results in errors.

## Execution

The user can execute flows locally, or remotely by a worker. Local execution generally means that you, the user, 
run your flow directly with a command like `python flow.py`. Remote execution generally means that a worker runs your flow 
through a [deployment](/3.0/deploy/infrastructure-examples/docker/) (optionally on different infrastructure).

With remote execution, the creation of your flow run happens separately from its execution. 
Flow runs are assigned to a work pool and a work queue. For flow runs to execute, a worker must be subscribed 
to the work pool and work queue, or the flow runs will go from `Scheduled` to `Late`. 
Ensure that your work pool and work queue have a subscribed worker.

Local and remote execution can also differ in their treatment of relative imports. 
If switching from local to remote execution results in local import errors, try replicating the 
behavior by executing the flow locally with the `-m` flag (For example, `python -m flow` instead of `python flow.py`). 
Read more about `-m` in this [Stack Overflow post](https://stackoverflow.com/a/62923810).

## API tests return an unexpected 307 Redirected

**Summary:** requests require a trailing `/` in the request URL.

If you write a test that does not include a trailing `/` when making a request to a specific endpoint:

```python
async def test_example(client):
    response = await client.post("/my_route")
    assert response.status_code == 201
```

You'll see a failure like:

```bash
E       assert 307 == 201
E        +  where 307 = <Response [307 Temporary Redirect]>.status_code
```

To resolve this, include the trailing `/`:

```python
async def test_example(client):
    response = await client.post("/my_route/")
    assert response.status_code == 201
```

Note: requests to nested URLs may exhibit the *opposite* behavior and require no trailing slash:

```python
async def test_nested_example(client):
    response = await client.post("/my_route/filter/")
    assert response.status_code == 307

    response = await client.post("/my_route/filter")
    assert response.status_code == 200
```

**Reference:** "HTTPX disabled redirect following by default" in 
[`0.22.0`](https://github.com/encode/httpx/blob/master/CHANGELOG.md#0200-13th-october-2021).

## `pytest.PytestUnraisableExceptionWarning` or `ResourceWarning`

As you're working with one of the `FlowRunner` implementations, you may get an
error like this:

```bash
E               pytest.PytestUnraisableExceptionWarning: Exception ignored in: <ssl.SSLSocket fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0>
E
E               Traceback (most recent call last):
E                 File ".../pytest_asyncio/plugin.py", line 306, in setup
E                   res = await func(**_add_kwargs(func, kwargs, event_loop, request))
E               ResourceWarning: unclosed <ssl.SSLSocket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 60605), raddr=('127.0.0.1', 6443)>

.../_pytest/unraisableexception.py:78: PytestUnraisableExceptionWarning

```

This error states that your test suite (or the `prefect` library code) opened a
connection to something (like a Docker daemon or a Kubernetes cluster) and didn't close
it.

It may help to re-run the specific test with `PYTHONTRACEMALLOC=25 pytest ...` so that
Python can display more of the stack trace where the connection was opened.