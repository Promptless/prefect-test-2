---
title: What's new in Prefect 3.0
sidebarTitle: What's new
---

Prefect 3.0 introduces a number of enhancements to the OSS product: a new events & automations backend for event-driven workflows and observability, improved runtime performance, autonomous task execution and a streamlined caching layer based on transactional semantics.

Most Prefect 2.0 users can upgrade without changes to their existing workflows. Please review the [upgrade guide](/3.0/resources/upgrade-to-prefect-3) for more information.

<Info>
**Prefect 2.0** refers to the 2.x lineage of the open source prefect package, and **Prefect 3.0** refers exclusively to the 3.x lineage of the prefect package. Neither version is strictly tied to any aspect of Prefect's commercial product, [Prefect Cloud](/3.0/manage/cloud). 
</Info>

## Open source events and automation system

One of the largest features in Prefect 3.0 is the introduction of the events and automation system to the open source package. Previously exclusive to Prefect Cloud, this system now allows all users to create event-driven workflows and automate their system based on the presence or absence of observable events. 

With this new capability, you can trigger actions based on specific event payloads, cancel runs if certain conditions aren't met, or automate workflow runs based on external events. For instance, you could initiate a data processing pipeline automatically when a new file lands in an S3 bucket. The system also enables you to receive notifications for various system health events, giving you greater visibility and control over your workflows.

## New transactional interface

Another major addition in Prefect 3.0 is the new transactional interface. This powerful feature makes it easier than ever to build resilient and idempotent pipelines. With the transactional interface, you can group tasks into transactions, automatically roll back side effects on failure, and significantly improve your pipeline's idempotency and resilience.

For example, you can define rollback behaviors for your tasks, ensuring that any side effects are cleanly reversed if a transaction fails. This is particularly useful for maintaining data consistency in complex workflows involving multiple steps or external systems.

## Flexible task execution

Prefect 3.0 has no restrictions on where tasks can run. Tasks can be nested within other tasks, allowing for more flexible and modular workflows; they can also be called outside of flows, essentially enabling Prefect to function as a background task service. You can now run tasks autonomously, apply them asynchronously, or delay their execution as needed. This flexibility opens up new possibilities for task management and execution strategies in your data pipelines.

## Enhanced client-side engine

Prefect 3.0 comes with a thoroughly reworked client-side engine that brings several improvements to the table. You can now nest tasks within other tasks, adding a new level of modularity to your workflows. The engine also supports generator tasks, allowing for more flexible and efficient handling of iterative processes.

One of the most significant changes is that all code now runs on the main thread by default. This change improves performance and leads to more intuitive behavior, especially when dealing with shared resources or non-thread-safe operations.

## Improved artifacts and variables

Prefect 3.0 enhances the artifacts system with new types, including progress bars and image artifacts. These additions allow for richer, more informative task outputs, improving the observability of your workflows.

The variables system has also been upgraded to support arbitrary JSON, not just strings. This expansion allows for more complex and structured data to be stored and retrieved as variables, increasing the flexibility of your workflow configurations.

## Workers

Workers were first introduced in Prefect 2.0 as next-generation agents, and are now standard in Prefect 3.0. Workers offer a stronger governance model for infrastructure, improved monitoring of jobs and work pool/queue health, and more flexibility in choosing compute layers, resulting in a more robust and scalable solution for managing the execution of your workflows across various environments.

Worker logs are now sent to the API only if a worker ID is present, indicating a connection to Prefect Cloud. This change simplifies the logging configuration and ensures logs are only sent when supported by the backend. The `PREFECT_EXPERIMENTS_WORKER_LOGGING_TO_API_ENABLED` environment variable has been removed, and users should update their configurations to align with the new logging behavior.

## Performance enhancements

Prefect 3.0 doesn't just bring new features; it also delivers significant performance improvements. Users running massively parallel workflows on distributed systems such as Dask and Ray will notice substantial speedups. In some benchmark cases, we've observed up to a 98% reduction in runtime overhead. These performance gains translate directly into faster execution times and more efficient resource utilization for your data pipelines.

## Release notes

See release notes for each released version in the [Gitub repository](https://github.com/PrefectHQ/prefect/releases).

## Quickstart

To upgrade to Prefect 3.0, run:

```bash
pip install -U prefect
```

If you self-host a Prefect server, run this command to update your database:

```bash
prefect server database upgrade
```

If you use a Prefect integration or extra, remember to upgrade it as well. For example:

```bash
pip install -U 'prefect[aws]'
```

## Upgrade notes

### Pydantic V2

<Info>
This change affects you if: you use custom Pydantic models with Prefect features.
</Info>

Prefect 3.0 is built with Pydantic 2.0 for improved performance. All Prefect objects will automatically upgrade, but if you use custom Pydantic models for flow parameters or custom blocks, you'll need to ensure they are compatible with Pydantic 2.0. You can continue to use Pydantic 1.0 models in your own code if they do not interact directly with Prefect.

Refer to [Pydantic's migration guide](https://docs.pydantic.dev/latest/migration/) for detailed information on necessary changes.

### Module location and name changes

Some less-commonly used modules have been renamed, reorganized, or removed for clarity. The old import paths will continue to be supported for 6 months, but emit deprecation warnings. You can look at the [deprecation code](https://github.com/PrefectHQ/prefect/blob/main/src/prefect/_internal/compatibility/migration.py) to see a full list of affected paths.

### Async tasks in synchronous flows

<info>
This change affects you if: you use advanced asynchronous behaviors in your flows.
</info>

In Prefect 2.0, it was possible to call native `async` tasks from synchronous flows, a pattern that is not normally supported in Python. Prefect 3.0.0 removes this behavior to reduce complexity and potential issues and edge cases. If you relied on asynchronous tasks in synchronous flows, you must either make your flow asynchronous or use a task runner that supports asynchronous execution. 

### Flow final states

<info>
This change affects you if: you want your flow to fail if any task in the flow fails, and you invoke your tasks in a way that doesn't automatically raise an error (including submitting them to a `TaskRunners`).
</info>

In Prefect 2.0, the final state of a flow run was influenced by the states of its task runs; if any task run failed, the flow run was marked as failed.

In Prefect 3.0, the final state of a flow run is entirely determined by:

1. The `return` value of the flow function (same as in Prefect 2.0):
   - Literal values are considered successful.
   - Any explicit `State` that is returned will be considered the final state of the flow run. If an iterable of `State` objects is returned, all must be `Completed` for the flow run to be considered `Completed`. If any are `Failed`, the flow run will be marked as `Failed`.

2. Whether the flow function allows an exception to `raise`:
   - Exceptions that are allowed to propagate will result in a `Failed` state.
   - Exceptions suppressed with `raise_on_failure=False` will not affect the flow run state.

This change means that task failures within a flow do not automatically cause the flow run to fail unless they affect the flow's return value or raise an uncaught exception.

<Warning>
When migrating from Prefect 2.0 to Prefect 3, be aware that flows may now complete successfully even if they contain failed tasks, unless you explicitly handle task failures.
</Warning>

To ensure your flow fails when critical tasks fail, consider these approaches:

1. Allow task exceptions to propagate by not using `raise_on_failure=False`.
2. Use `return_state=True` and explicitly check task states to conditionally `raise` the underlying exception or return a failed state.
3. Use try/except blocks to handle task failures and return appropriate states.

#### Examples

<CodeGroup>
```python Allow Unhandled Exceptions
from prefect import flow, task

@task
def failing_task():
    raise ValueError("Task failed")

@flow
def my_flow():
    failing_task()  # Exception propagates, causing flow failure

try:
    my_flow()
except ValueError as e:
    print(f"Flow failed: {e}")  # Output: Flow failed: Task failed
```

```python Use return_state
from prefect import flow, task
from prefect.states import Failed

@task
def failing_task():
    raise ValueError("Task failed")

@flow
def my_flow():
    state = failing_task(return_state=True)
    if state.is_failed():
        raise ValueError(state.result())
    return "Flow completed successfully"

try:
    print(my_flow())
except ValueError as e:
    print(f"Flow failed: {e}")  # Output: Flow failed: Task failed
```

```python Use try/except
from prefect import flow, task
from prefect.states import Failed

@task
def failing_task():
    raise ValueError("Task failed")

@flow
def my_flow():
    try:
        failing_task()
    except ValueError:
        return Failed(message="Flow failed due to task failure")
    return "Flow completed successfully"

print(my_flow())  # Output: Failed(message='Flow failed due to task failure')
```
</CodeGroup>

Choose the strategy that best fits your specific use case and error handling requirements.

-----

### Futures interface

<info>
This change affects you if: you directly interact with `PrefectFuture` objects.
</info>

PrefectFutures now have a standard synchronous interface, with an asynchronous one [planned soon](https://github.com/PrefectHQ/prefect/issues/15008).

### Automatic task caching

<info>
This change affects you if: you rely on side effects in your tasks
</info>

Prefect 3.0 introduces a powerful idempotency engine. By default, tasks in a flow run are automatically cached if they are called more than once with the same inputs. If you rely on tasks with side effects, this may result in surprising behavior. To disable caching, pass `cache_policy=None` to your task.

### Workers

<info>
This change affects you if: you're using agents from an early version of Prefect 2.0.
</info>

In Prefect 2.0, agents were deprecated in favor of next-generation workers. Workers are now standard in Prefect 3. For detailed information on upgrading from agents to workers, please refer to our [upgrade guide](https://docs-3.prefect.io/3.0/resources/upgrade-agents-to-workers).

### Resolving common gotchas

#### `AttributeError: 'coroutine' object has no attribute <some attribute>`

When within an asynchronous task or flow context, if you do **not** `await` an asynchronous function or method, this error will be raised when you try to use the object.

To fix it, `await` the asynchronous function or method or use `_sync=True`.

For example, `Block`'s `load` method is asynchronous in an async context:
<CodeGroup>
```python Incorrect
from prefect.blocks.system import Secret

async def my_async_function():
    my_secret = Secret.load("my-secret")
    print(my_secret.get()) # AttributeError: 'coroutine' object has no attribute 'get'
```

```python Correct
from prefect.blocks.system import Secret

async def my_async_function():
    my_secret = await Secret.load("my-secret")
    print(my_secret.get()) # This will work
```

```python Also Correct
from prefect.blocks.system import Secret

async def my_async_function():
    my_secret = Secret.load("my-secret", _sync=True)
    print(my_secret.get()) # This will work
```

</CodeGroup>

Similarly, if you never use an un-awaited coroutine, you may see a warning like this:

```python
RuntimeWarning: coroutine 'some_async_callable' was never awaited
...
RuntimeWarning: Enable tracemalloc to get the object allocation traceback
```

This is the same problem as above, and you may `await` the coroutine to fix it or use `_sync=True`.

#### `TypeError: object <some Type> can't be used in 'await' expression`

This error occurs when using the `await` keyword before an object that is not a coroutine.

To fix it, remove the `await`.

For example, `my_task.submit(...)` is _always_ synchronous in Prefect 3.x:

<CodeGroup>
```python Incorrect
from prefect import flow, task

@task
async def my_task():
    pass

@flow
async def my_flow():
    future = await my_task.submit() # TypeError: object PrefectConcurrentFuture can't be used in 'await' expression
```

```python Correct
from prefect import flow, task

@task
async def my_task():
    pass

@flow
async def my_flow():
    future = my_task.submit() # This will work
```
</CodeGroup>

See the [Futures interface section](#futures-interface) for more information on this particular gotcha.

#### `TypeError: Flow.deploy() got an unexpected keyword argument 'schedule'`

In Prefect 3.0, the `schedule` argument has been removed in favor of the `schedules` argument.

This applies to both the `Flow.serve` and `Flow.deploy` methods.

<CodeGroup>
```python Prefect 2.0 {11}
from datetime import timedelta
from prefect import flow
from prefect.client.schemas.schedules import IntervalSchedule

@flow
def my_flow():
    pass

my_flow.serve(
    name="my-flow",
    schedule=IntervalSchedule(interval=timedelta(minutes=1))
)
```

```python Prefect 3.0 {11}
from datetime import timedelta
from prefect import flow
from prefect.client.schemas.schedules import IntervalSchedule

@flow
def my_flow():
    pass

my_flow.serve(
    name="my-flow",
    schedules=[IntervalSchedule(interval=timedelta(minutes=1))]
)
```
</CodeGroup>
