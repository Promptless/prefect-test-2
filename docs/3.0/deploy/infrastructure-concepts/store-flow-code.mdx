---
title: Retrieve code from storage
description: Learn about where to store your flow code.
---

When a deployment runs, the execution environment needs access to the flow code.
Flow code is not stored in Prefect server or Prefect Cloud.

You have several flow code storage options for remote execution:
- Git-based storage (GitHub, GitLab, Bitbucket)
- Docker image-based storage
- Cloud-provider storage (AWS S3, Azure Blob Storage, GCP GCS)

Each of these options is popular - your choice will depend upon your team's needs and tools.

Local storage is also an option for deployments that run locally.

In the examples below, we show how to create a work pool-based deployment for each of these storage options. 

## Deployment creation options
You can create a deployment through [Python code with the `flow.deploy` method](/3.0/deploy/infrastructure-concepts/deploy-via-python) or through a [YAML specification defined in a `prefect.yaml` file](/3.0/deploy/infrastructure-concepts/prefect-yaml).

When using the Python `deploy` method specify a flow storage location other than a Docker image requires the `flow.from_source` method. The `source` and `entrypoint` arguments are required. 

The `entrypoint` is the path to the file the flow is located in and the function name, separated by a colon.

The `source` is either a URL to a git repository or a storage object.

To create a `prefect.yaml` file interactively, run `prefect deploy` from the CLI and select the appropriate storage option.

## Git-based storage

Git-based version control platforms provide redundancy, version control, and collaboration capabilities. Prefect supports:

- [GitHub](https://github.com/)
- [GitLab](https://www.gitlab.com)
- [Bitbucket](https://bitbucket.org/)

For a public repository, you can use the repository URL directly.

If you are using a private repository and are authenticated in your environment at deployment creation and deployment execution, you can use the repository URL directly.

Alternatively, for a private repository, you can create a `Secret` block or create a credentials block specific to your git-based version control platform to store your credentials. 
Then you can reference the block in the Python `deploy` method or the `prefect.yaml` file pull step.

If using the Python `deploy` method with a private repository that references a block, provide a [`GitRepository`](https://prefect-python-sdk-docs.netlify.app/prefect/flows/#prefect.runner.storage.GitRepository) object instead of a URL, as shown below.

<Tabs>
  <Tab title="GitHub">

    <CodeGroup>

    ```python gh_no_block.py
    from prefect import flow

    if __name__ == "__main__":
        flow.from_source(
            source="https://github.com/org/my-public-repo.git",
            entrypoint="gh_no_block.py:my_flow",
        ).deploy(
            name="my-github-deployment",
            work_pool_name="my_pool",
        )
    ```

    ```python gh_credentials_block.py
    from prefect import flow
    from prefect.runner.storage import GitRepository
    from prefect_github import GitHubCredentials


    if __name__ == "__main__":

        github_repo = GitRepository(
            url="https://github.com/org/my-private-repo.git",
            credentials=GitHubCredentials.load("my-github-credentials-block"),
        )

        flow.from_source(
            source=github_repo,
            entrypoint="gh_credentials_block.py:my_flow",
        ).deploy(
            name="private-github-deploy",
            work_pool_name="my_pool",
        )
    ```

    ```python gh_secret_block.py
    from prefect import flow
    from prefect.runner.storage import GitRepository
    from prefect.blocks.system import Secret


    if __name__ == "__main__":

        github_repo = GitRepository(
            url="https://github.com/org/my-private-repo.git",
            credentials={
                "access_token": Secret.load("my-secret-block-with-my-gh-credentials")
            },
        )

        flow.from_source(
            source=github_repo,
            entrypoint="gh_secret_block.py:my_flow",
        ).deploy(
            name="private-github-deploy",
            work_pool_name="my_pool",
        )
    ```

    ```yaml prefect.yaml
    # relevant section of the file:
    pull:
        - prefect.deployments.steps.git_clone:
            repository: https://gitlab.com/org/my-repo.git
            # Uncomment the following line if using a credentials block
            # credentials: "{{ prefect.blocks.github-credentials.my-github-credentials-block }}"
            # Uncomment the following line if using a Secret block
            # access_token: "{{ prefect.blocks.secret.my-block-name }}"
    ```
    </CodeGroup>

    For accessing a private repository, we suggest creating a personal access token.
    We recommend using HTTPS with [fine-grained Personal Access Tokens](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens#creating-a-fine-grained-personal-access-token) to limit access by repository. 
    
    See the GitHub docs for [Personal Access Tokens (PATs)](https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token).

    Under *Your Profile -> Developer Settings -> Personal access tokens -> Fine-grained token* choose *Generate New Token* and 
    fill in the required fields. 
    
    Under *Repository access* choose *Only select repositories* and grant the token permissions for *Contents*.

    If using a Secret block, you can create it through code or the UI ahead of time and reference it at deployment creation as shown above. 

    If using a credentials block, you can create it ahead of time and reference it at deployment creation. 

    1. Install prefect-github with `pip install -U prefect-github`
    1. Register the blocks in that library to make them available on the server with `prefect block register -m prefect_github`
    1. Create a GitHub Credentials block through code or the Prefect UI and reference it at deployment creation as shown above.

  </Tab>  
  <Tab title="Bitbucket">
    <CodeGroup>

    ```python bb_no_block.py
    from prefect import flow


    if __name__ == "__main__":
        flow.from_source(
            source="https://bitbucket.com/org/my-public-repo.git",
            entrypoint="bb_no_block.py:my_flow",
        ).deploy(
            name="my-bitbucket-deployment",
            work_pool_name="my_pool",
        )
    ```

    ```python bb_credentials_block.py

    from prefect import flow
    from prefect.runner.storage import GitRepository
    from prefect_bitbucket import BitBucketCredentials

    if __name__ == "__main__":

        github_repo = GitRepository(
            url="https://bitbucket.com/org/my-private-repo.git",
            credentials=BitBucketCredentials.load("my-bitbucket-credentials-block")
        )

        flow.from_source(
            source=source,
            entrypoint="bb_credentials_block.py:my_flow",
        ).deploy(
            name="private-bitbucket-deploy",
            work_pool_name="my_pool",
        )
    ```

    ```python bb_secret_block.py

    from prefect import flow
    from prefect.runner.storage import GitRepository
    from prefect.blocks.system import Secret


    if __name__ == "__main__":
        github_repo=GitRepository(
            url="https://bitbucket.com/org/my-private-repo.git",
            credentials={
                "access_token": Secret.load("my-secret-block-with-my-bb-credentials")
            },
        )
        
        flow.from_source(
            source=github_repo,
            entrypoint="bb_secret_block.py:my_flow",
        ).deploy(
            name="private-bitbucket-deploy",
            work_pool_name="my_pool",
        )
    ```

    ```yaml prefect.yaml
    # relevant section of the file:
    pull:
        - prefect.deployments.steps.git_clone:
            repository: https://bitbucket.org/org/my-private-repo.git
            # Uncomment the following line if using a credentials block
            # credentials: "{{ prefect.blocks.bitbucket-credentials.my-bitbucket-credentials-block }}"
            # Uncomment the following line if using a Secret block
            # access_token: "{{ prefect.blocks.secret.my-block-name }}"
    ```
    </CodeGroup>

    For accessing a private repository, we recommend using HTTPS with Repository, Project, or Workspace [Access Tokens](https://support.atlassian.com/bitbucket-cloud/docs/access-tokens/). 
    
    You can create a Repository Access Token with Scopes -> Repositories -> Read.

    Bitbucket requires you prepend the token string with `x-token-auth:` The full string looks like this: `x-token-auth:abc_123_this_is_a_token`. 

    If using a Secret block, you can create it through code or the UI ahead of time and reference it at deployment creation as shown above. 

    If using a credentials block, you can create it ahead of time and reference it at deployment creation. 

    1. Install prefect-bitbucket with `pip install -U prefect-bitbucket`
    1. Register the blocks in that library with `prefect block register -m prefect_bitbucket` 
    1. Create a Bitbucket credentials block in code or the Prefect UI and reference at deployment creation as shown above.

  </Tab>

<Tab title="GitLab">

    <CodeGroup>

    ```python gl_no_block.py
    from prefect import flow


    if __name__ == "__main__":
        gitlab_repo = "https://gitlab.com/org/my-public-repo.git"

        flow.from_source(
            source=gitlab_repo,
            entrypoint="gl_no_block.py:my_flow"
        ).deploy(
            name="my-gitlab-deployment",
            work_pool_name="my_pool",
        )
    ```

    ```python gl_credentials_block.py

    from prefect import flow
    from prefect.runner.storage import GitRepository
    from prefect_gitlab import GitLabCredentials


    if __name__ == "__main__":

        gitlab_repo = GitRepository(
            url="https://gitlab.com/org/my-private-repo.git",
            credentials=GitLabCredentials.load("my-gitlab-credentials-block")
        )
        
        flow.from_source(
            source=gitlab_repo,
            entrypoint="gl_credentials_block.py:my_flow",
        ).deploy(
            name="private-gitlab-deploy",
            work_pool_name="my_pool",
        )
    ```

    ```python gl_secret_block.py    

    from prefect import flow
    from prefect.runner.storage import GitRepository
    from prefect.blocks.system import Secret


    if __name__ == "__main__":
        gitlab_repo = GitRepository(
            url="https://gitlab.com/org/my-private-repo.git",
            credentials={
                "access_token": Secret.load("my-secret-block-with-my-gl-credentials")
            },
        )

        flow.from_source(   
            source=gitlab_repo,
            entrypoint="gl_secret_block.py:my_flow",
        ).deploy(
            name="private-gitlab-deploy",
            work_pool_name="my_pool",
        )
    ```

    ```yaml prefect.yaml
    # relevant section of the file:
    pull:
        - prefect.deployments.steps.git_clone:
            repository: https://gitlab.com/org/my-private-repo.git
            # Uncomment the following line if using a credentials block
            # credentials: "{{ prefect.blocks.gitlab-credentials.my-gitlab-credentials-block }}"
            # Uncomment the following line if using a Secret block
            # access_token: "{{ prefect.blocks.secret.my-block-name }}"
    ```
    </CodeGroup>

    For accessing a private repository, we recommend using HTTPS with [Project Access Tokens](https://docs.gitlab.com/ee/user/profile/personal_access_tokens.html).

    In your repository in the GitLab UI, select *Settings -> Repository -> Project Access Tokens* and check 
    *read_repository* under *Select scopes*.

    If using a Secret block, you can create it through code or the UI ahead of time and reference it at deployment creation as shown above. 

    If using a credentials block, you can create it ahead of time and reference it at deployment creation. 

    1. Install prefect-gitlab with `pip install -U prefect-gitlab`
    1. Register the blocks in that library with `prefect block register -m prefect_gitlab` 
    1. Create a GitLab credentials block in code or the Prefect UI and reference it at deployment creation as shown above.

  </Tab>
</Tabs>

Note that you can specify a `branch` if creating a `GitRepository` object. 
The default is `"main"`.

<Warning>
**Push your code**

When you make a change to your code, Prefect does not push your code to your git-based version control platform.
You need to push your code manually or as part of your CI/CD pipeline.
This is intentional to avoid confusion about the git history and push process.
</Warning>

---
title: What's new in Prefect 3.0
sidebarTitle: What's new
---

Prefect 3.0 introduces a number of enhancements to the OSS product: a new events & automations backend for event-driven workflows and observability, improved runtime performance, autonomous task execution and a streamlined caching layer based on transactional semantics.

Most Prefect 2.0 users can upgrade without changes to their existing workflows. Please review the [upgrade guide](/3.0/resources/upgrade-to-prefect-3) for more information.

<Info>
**Prefect 2.0** refers to the 2.x lineage of the open source prefect package, and **Prefect 3.0** refers exclusively to the 3.x lineage of the prefect package. Neither version is strictly tied to any aspect of Prefect's commercial product, [Prefect Cloud](/3.0/manage/cloud). 
</Info>

## Open source events and automation system

One of the largest features in Prefect 3.0 is the introduction of the events and automation system to the open source package. Previously exclusive to Prefect Cloud, this system now allows all users to create event-driven workflows and automate their system based on the presence or absence of observable events. 

With this new capability, you can trigger actions based on specific event payloads, cancel runs if certain conditions aren't met, or automate workflow runs based on external events. For instance, you could initiate a data processing pipeline automatically when a new file lands in an S3 bucket. The system also enables you to receive notifications for various system health events, giving you greater visibility and control over your workflows.

## New transactional interface

Another major addition in Prefect 3.0 is the new transactional interface. This powerful feature makes it easier than ever to build resilient and idempotent pipelines. With the transactional interface, you can group tasks into transactions, automatically roll back side effects on failure, and significantly improve your pipeline's idempotency and resilience.

For example, you can define rollback behaviors for your tasks, ensuring that any side effects are cleanly reversed if a transaction fails. This is particularly useful for maintaining data consistency in complex workflows involving multiple steps or external systems.

## Flexible task execution

Prefect 3.0 has no restrictions on where tasks can run. Tasks can be nested within other tasks, allowing for more flexible and modular workflows; they can also be called outside of flows, essentially enabling Prefect to function as a background task service. You can now run tasks autonomously, apply them asynchronously, or delay their execution as needed. This flexibility opens up new possibilities for task management and execution strategies in your data pipelines.

## Enhanced client-side engine

Prefect 3.0 comes with a thoroughly reworked client-side engine that brings several improvements to the table. You can now nest tasks within other tasks, adding a new level of modularity to your workflows. The engine also supports generator tasks, allowing for more flexible and efficient handling of iterative processes.

One of the most significant changes is that all code now runs on the main thread by default. This change improves performance and leads to more intuitive behavior, especially when dealing with shared resources or non-thread-safe operations.

## Improved artifacts and variables

Prefect 3.0 enhances the artifacts system with new types, including progress bars and image artifacts. These additions allow for richer, more informative task outputs, improving the observability of your workflows.

The variables system has also been upgraded to support arbitrary JSON, not just strings. This expansion allows for more complex and structured data to be stored and retrieved as variables, increasing the flexibility of your workflow configurations.

## Workers

Workers were first introduced in Prefect 2.0 as next-generation agents, and are now standard in Prefect 3.0. Workers offer a stronger governance model for infrastructure, improved monitoring of jobs and work pool/queue health, and more flexibility in choosing compute layers, resulting in a more robust and scalable solution for managing the execution of your workflows across various environments.

Worker logs are now sent to the API only if a worker ID is present, indicating a connection to Prefect Cloud. This change simplifies the logging configuration and ensures logs are only sent when supported by the backend. The `PREFECT_EXPERIMENTS_WORKER_LOGGING_TO_API_ENABLED` environment variable has been removed, and users should update their configurations to align with the new logging behavior.

## Performance enhancements

Prefect 3.0 doesn't just bring new features; it also delivers significant performance improvements. Users running massively parallel workflows on distributed systems such as Dask and Ray will notice substantial speedups. In some benchmark cases, we've observed up to a 98% reduction in runtime overhead. These performance gains translate directly into faster execution times and more efficient resource utilization for your data pipelines.

## Release notes

See release notes for each released version in the [Gitub repository](https://github.com/PrefectHQ/prefect/releases).

## Cloud-provider storage

Another option for flow code storage is any [fsspec](https://filesystem-spec.readthedocs.io/en/latest/)-supported storage location, such as AWS S3, Azure Blob Storage, or GCP GCS.

If the storage location is publicly available, or if you are authenticated in the environment where you are creating and running your deployment, you can reference the storage location directly. 
You don't need to pass credentials explicitly.

To pass credentials explicitly to authenticate to your storage location, you can use either of the following block types:

- Prefect integration library storage blocks, such as the `prefect-aws` library's `S3Bucket` block, which can use a `AWSCredentials` block when it is created.
- Secret blocks

<Note>
If you use a storage block such as the `S3Bucket` block, you need to have the `prefect-aws` library available in the environment where your flow code runs.

You can do any of the following to make the library available:

1. Install the library into the execution environment directly
1. Specify the library in the work pool's Base Job Template in the **Environment Variables** section like this:`{"EXTRA_PIP_PACKAGES":"prefect-aws"}`
1. Specify the library in the environment variables of the `deploy` method as shown in the examples below
1. Specify the library in a `requirements.txt` file and reference the file in the `pull` step of the `prefect.yaml` file like this:

```yaml
    - prefect.deployments.steps.pip_install_requirements:
        directory: "{{ pull_code.directory }}" 
        requirements_file: requirements.txt
```

</Note>

The examples below show how to create a deployment with flow code in a cloud provider storage location.
For each example, we show how to access code that is publicly available.
The `prefect.yaml` example includes an additional line to reference a credentials block if authenticating to a private storage location through that option. 

We also include Python code that shows how to use an existing storage block and an example of that creates, but doesn't save, a storage block that references an existing nested credentials block.


<Tabs>
  <Tab title="AWS S3 bucket">

    <CodeGroup>

    ```python s3_no_block.py
    from prefect import flow


    if __name__ == "__main__":
        flow.from_source(
            source="s3://my-bucket/my-folder",
            entrypoint="my_file.py:my_flow",
        ).deploy(
            name="my-aws-s3-deployment",
            work_pool_name="my-work-pool"
        )
    ```

    ```python s3_block.py

    from prefect import flow
    from prefect_aws.s3 import S3Bucket

    if __name__ == "__main__":
        s3_bucket_block = S3Bucket.load("my-code-storage-block")

        # or:
        # s3_bucket_block = S3Bucket(
        #     bucket="my-bucket",
        #     folder="my-folder",
        #     credentials=AWSCredentials.load("my-credentials-block")
        # )

        flow.from_source(
            source=s3_bucket_block, 
            entrypoint="my_file.py:my_flow"
        ).deploy(
            name="my-aws-s3-deployment", 
            work_pool_name="my-work-pool"
            job_variables={"env": {"EXTRA_PIP_PACKAGES": "prefect-aws"} }, 
        )
    ```

    ```yaml prefect.yaml
    build: null

    push:
    - prefect_aws.deployments.steps.push_to_s3:
        id: push_code
        requires: prefect-aws>=0.5
        bucket: my-bucket
        folder: my-folder
        credentials: "{{ prefect.blocks.aws-credentials.my-credentials-block }}" # if explicit authentication is required

    pull:
    - prefect_aws.deployments.steps.pull_from_s3:
        id: pull_code
        requires: prefect-aws>=0.5
        bucket: '{{ push_code.bucket }}'
        folder: '{{ push_code.folder }}'
        credentials: "{{ prefect.blocks.aws-credentials.my-credentials-block }}" # if explicit authentication is required 
    
    deployments:
    - name: my-aws-deployment
      version: null
      tags: []
      concurrency_limit: null
      description: null
      entrypoint: my_file.py:my_flow
      parameters: {}
      work_pool:
        name: my-work-pool
        work_queue_name: null
        job_variables: {}
      enforce_parameter_schema: true
      schedules: []
    ``` 

    </CodeGroup>

    To create an `AwsCredentials` block:

    1. Install the [prefect-aws](/integrations/prefect-aws) library with `pip install -U prefect-aws`
    1. Register the blocks in prefect-aws with `prefect block register -m prefect_aws` 
    1. Create a user with a role with read and write permissions to access the bucket. If using the UI, create an access key pair with *IAM -> Users -> Security credentials -> Access keys -> Create access key*. Choose *Use case -> Other* and then copy the *Access key* and *Secret access key* values.
    1. Create an [`AWSCredentials` block](/integrations/prefect-aws/index#save-credentials-to-an-aws-credentials-block) in code or the Prefect UI. In addition to the block name, most users will fill in the *AWS Access Key ID* and *AWS Access Key Secret* fields.
    1. Reference the block as shown above.
    

  </Tab>
  <Tab title="Azure Blob Storage container">

    <CodeGroup>

    ```python azure_no_block.py
    from prefect import flow


    if __name__ == "__main__":
        flow.from_source(
            source="az://mycontainer/myfolder",
            entrypoint="my_file.py:my_flow",
        ).deploy(
            name="my-azure-deployment",
            work_pool_name="my-work-pool",
            job_variables={"env": {"EXTRA_PIP_PACKAGES": "prefect-azure"} }, 
        )
    ```

    ```python azure_block.py
    from prefect import flow
    from prefect_azure import AzureBlobCredentials, AzureBlobStorage


    if __name__ == "__main__":

        azure_blob_storage_block = AzureBlobStorage.load("my-code-storage-block")

        # or 
        # azure_blob_storage_block = AzureBlobStorage(   
        #     container="my-prefect-azure-container",
        #     folder="my-folder",
        #     credentials=AzureBlobCredentials.load("my-credentials-block")
        # )

        flow.from_source(source=azure_blob_storage_block, entrypoint="my_file.py:my_flow").deploy(
            name="my-azure-deployment", work_pool_name="my-work-pool"
        )
    ```

    ```yaml prefect.yaml
    build: null

    push:
    - prefect_azure.deployments.steps.push_to_azure_blob_storage:
        id: push_code
        requires: prefect-azure>=0.4
        container: my-prefect-azure-container
        folder: my-folder
        credentials: "{{ prefect.blocks.azure-blob-storage-credentials.my-credentials-block }}" 
        # if explicit authentication is required

    pull:
    - prefect_azure.deployments.steps.pull_from_azure_blob_storage:
        id: pull_code
        requires: prefect-azure>=0.4
        container: '{{ push_code.container }}'
        folder: '{{ push_code.folder }}'
        credentials: "{{ prefect.blocks.azure-blob-storage-credentials.my-credentials-block }}" # if explicit authentication is required
    
    deployments:
    - name: my-azure-deployment
      version: null
      tags: []
      concurrency_limit: null
      description: null
      entrypoint: my_file.py:my_flow
      parameters: {}
      work_pool:
        name: my-work-pool
        work_queue_name: null
        job_variables: {}
      enforce_parameter_schema: true
      schedules: []
    ```

    </CodeGroup>

    To create an `AzureBlobCredentials` block:

    1. Install the [prefect-azure](/integrations/prefect-azure/) library with `pip install -U prefect-azure`
    1. Register the blocks in prefect-azure with `prefect block register -m prefect_azure` 
    1. Create an access key for a role with sufficient (read and write) permissions to access the blob. 
    You can create a connection string containing all required information in the UI under *Storage Account -> Access keys*.
    1. Create an Azure Blob Storage Credentials block in code or the Prefect UI. Enter a name for the block and paste the 
    connection string into the *Connection String* field.
    1. Reference the block as shown above.
  </Tab>
  <Tab title="GCP GCS bucket">

    <CodeGroup>

    ```python gcs_no_block.py
    from prefect import flow


    if __name__ == "__main__":
        flow.from_source(
            source="gs://my-bucket/my-folder",  
            entrypoint="my_file.py:my_flow",
        ).deploy(
            name="my-gcs-deployment",
            work_pool_name="my-work-pool"
        )
    ```

    ```python gcs_block.py
    from prefect import flow
    from prefect_gcp import GcpCredentials, GCSBucket


    if __name__ == "__main__":

        gcs_bucket_block = GCSBucket.load("my-code-storage-block")

        # or 
        # gcs_bucket_block = GCSBucket(
        #     bucket="my-bucket",
        #     folder="my-folder",
        #     credentials=GcpCredentials.load("my-credentials-block")
        # )

        flow.from_source(
            source=gcs_bucket_block,
            entrypoint="my_file.py:my_flow",
        ).deploy(
            name="my-gcs-deployment",
            work_pool_name="my_pool",
            job_variables={"env": {"EXTRA_PIP_PACKAGES": "prefect-gcp"} }, 
        )
    ```

    ```yaml prefect.yaml
    build: null

    push:
    - prefect_gcp.deployment.steps.push_to_gcs:
        id: push_code
        requires: prefect-gcp>=0.6
        bucket: my-bucket
        folder: my-folder
        credentials: "{{ prefect.blocks.gcp-credentials.my-credentials-block }}" # if explicit authentication is required 

    pull:
    - prefect_gcp.deployment.steps.pull_from_gcs:
        id: pull_code
        requires: prefect-gcp>=0.6
        bucket: '{{ push_code.bucket }}'
        folder: '{{ pull_code.folder }}'
        credentials: "{{ prefect.blocks.gcp-credentials.my-credentials-block }}" # if explicit authentication is required 
    
    deployments:
    - name: my-gcs-deployment
        version: null
        tags: []
        concurrency_limit: null
        description: null
        entrypoint: my_file.py:my_flow
        parameters: {}
        work_pool:
          name: my-work-pool
          work_queue_name: null
          job_variables: {}
        enforce_parameter_schema: true
        schedules: []
    ```
    </CodeGroup>
    
     To create a `GcpCredentials` block:

    1. Install the [prefect-gcp](/integrations/prefect-gcp/) library with `pip install -U prefect-gcp`
    1. Register the blocks in prefect-gcp with `prefect block register -m prefect_gcp` 
    1. Create a service account in GCP for a role with read and write permissions to access the bucket contents. 
    If using the GCP console, go to *IAM & Admin -> Service accounts -> Create service account*. 
    After choosing a role with the required permissions, 
    see your service account and click on the three dot menu in the *Actions* column. 
    Select *Manage Keys -> ADD KEY -> Create new key -> JSON*. Download the JSON file.
    1. Create a GCP Credentials block in code or the Prefect UI. Enter a name for the block and paste the entire contents of the JSON key file into the *Service Account Info* field.
    1. Reference the block as shown above.
    </Tab>
</Tabs>

Another authentication option is to give the [worker](/3.0/deploy/infrastructure-concepts/workers/) access to the storage location at runtime through SSH keys.

## Store code locally

If using a Process work pool, you can use one of the remote code storage options shown above, or you can store your flow code in a local folder.

Here is an example of how to create a deployment with flow code stored locally:

<CodeGroup>

```python local_process_deploy_local_code.py
from prefect import flow
from pathlib import Path


@flow(log_prints=True)
def my_flow(name: str = "World"):
    print(f"Hello {name}!")
    print(str(Path(__file__).parent))  # dynamic path


if __name__ == "__main__":
    my_flow.from_source(
        source=str(Path(__file__).parent),  # code stored in local directory
        entrypoint="local_process_deploy_local_code.py:my_flow",
    ).deploy(
        name="local-process-deploy-local-code",
        work_pool_name="my-process-pool",
    )
```

```yaml prefect.yaml
build: null

push: null

pull:
- prefect.deployments.steps.set_working_directory:
    directory: /my_directory

deployments:
- name: local-process-deploy-local-code
  version: null
  tags: []
  concurrency_limit: null
  description: null
  entrypoint: local_process_deploy_local_code.py:my_flow
  parameters: {}
  work_pool:
    name: my-process-pool
    work_queue_name: null
    job_variables: {}
  enforce_parameter_schema: true
  schedules: []
```
</CodeGroup>

## Include or exclude files from storage

By default, Prefect includes all files in the current folder when you create a deployment.

When using a git repository, Docker image, or cloud-provider storage location, you may want to exclude certain files or directories. 
If you are familiar with Docker you are likely familiar with the [`.dockerignore`](https://docs.docker.com/engine/reference/builder/#dockerignore-file) file. 
For remote storage, the `.prefectignore` file serves the same purpose and follows a similar syntax. 
For example, an entry of `*.pyc` will exclude all `.pyc` files from upload.

## Update flow code

After creating a deployment, you may need to change your flow code.
If baking your flow code into a Docker image, you will need to rebuild your image.
If storing your flow code in a git-based version control platform or a cloud-based storage location, often you can update your flow code without rebuilding your deployment.

The exception is when something the server needs to know about has changed, such as the flow entrypoint parameters.

Rerun the Python script with `deploy` or run `prefect deploy` from the CLI for YAML-based deployments to update your deployment with the new flow code.

## Flow code storage for deployments created with `serve` 

The Python `serve` method creates a deployment and a local long-running process to poll for flow runs at the same time.

The deployment creation mechanics for `serve` are similar to `deploy`. 
`deploy`just requires a work pool name and has a number of parameters dealing with flow code storage for Docker images.

Unlike `serve`, if you don't specify an image to use for your flow, you must specify where to pull the flow code from at runtime with the `from_source` method; `from_source` is optional with `serve`.

Read more about when to consider using `serve` [here](/3.0/deploy/infrastructure-concepts/deploy-via-python#when-to-consider-flow-deploy-over-flow-serve).
